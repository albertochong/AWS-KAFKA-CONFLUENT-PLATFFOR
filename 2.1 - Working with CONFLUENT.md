
# Working with CONFLUENT KAFKA basics

## Reference KAFKA commands 
###  

## Run in Terminal

* Show topics parameters
```bash
 kafka-topics
```

* Create topic with 3 partitions 
```bash
 kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic TpBusLisbonStatus
```

* Describe one topic
```bash
 kafka-topics --describe --zookeeper localhost:2181 --topic TpBusLisbonStatus
```

* Creating messages with producer.
```bash
kafka-console-producer --broker-list ec2-18-217-55-153.us-east-2.compute.amazonaws.com:9092 --topic TpTest
```

* Consumer messages with consumer console
```bash
kafka-console-consumer --bootstrap-server ec2-18-217-55-153.us-east-2.compute.amazonaws.com:9092 --topic TpTeste --from-beginning
```

* Generate some data.
```bash
ksql-datagen bootstrap-server=ec2-18-217-55-153.us-east-2.compute.amazonaws.com:9092 schema=datagen/userprofile.avro key-format=json value-format=json topic=TpTeste key=userid maxInterval=5000 iterations=10000
```

* Create connector source with JDBC to SQL instance, get data and write to topic first with bulkload and after incrememtal and update
```bash
1 - list existing connectors 
    confluent local list connectors

```
![alt text](https://achong.blob.core.windows.net/certificates/list_connectors.PNG)

2 - Go to <CONFLUENTE_HOME>/etc/etc/kafka-connect-jdbc   and create your connecto to SQL SERVER instance to get data to topic
nano source-sqlserver-dbLisbonMetropolitan.properties


